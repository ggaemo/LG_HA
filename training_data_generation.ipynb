{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data(data_type):\n",
    "    df = pd.read_csv('{}/EVO_Training_Data_Original.csv'.format(data_type), index_col=False)\n",
    "\n",
    "    time = df.apply(lambda x: str(int(x['date '])) +' ' +str(int(x['H'])) + ':' +str(int(x['M'])) + ':' + str(int(x['S'])), axis=1)\n",
    "    datetime = time.apply(parser.parse)\n",
    "    df['datetime'] = datetime\n",
    "\n",
    "    row_list = list()\n",
    "    step_size = 5\n",
    "    skip_num = 0\n",
    "    for i in range(len(df) - step_size):    \n",
    "        skip_time = False\n",
    "        tmp = df['datetime'].iloc[i:i+step_size] \n",
    "        cap_nom = df['cap_nom'].iloc[i:i+step_size]\n",
    "        first = tmp.iloc[0]\n",
    "        if len(cap_nom.unique()) == 1:\n",
    "            for idx, j in tmp.iteritems():            \n",
    "                if j - first > timedelta( minutes=12):                \n",
    "                    skip_num +=1\n",
    "                    skip_time = True\n",
    "                    break\n",
    "                else:\n",
    "                    first = j\n",
    "            if not skip_time:\n",
    "                row_list.append(df.iloc[i:i+step_size])\n",
    "    print('skipped :', skip_num)\n",
    "\n",
    "    columns = ['mdot', 'Tod', 'RHod', 'mode', 'Tid', 'Vidu', 'cap_nom', 'Qsens', 'Qlat']\n",
    "    data = np.zeros((len(row_list * step_size), len(columns)))\n",
    "    for idx, value in enumerate(row_list):\n",
    "        data[idx * (step_size) :(idx + 1)* (step_size)] = value[columns].values    \n",
    "\n",
    "    data = data.reshape(-1, step_size, len(columns))\n",
    "\n",
    "    target_columns = ['Load_s', 'Load_l']\n",
    "    target = np.zeros((len(row_list) * step_size, len(target_columns)))\n",
    "    for idx, value in enumerate(row_list):\n",
    "        target[idx * (step_size) :(idx + 1)* (step_size)] = value[target_columns].values\n",
    "\n",
    "    target = target.reshape(-1, step_size, len(target_columns))\n",
    "\n",
    "    target = target[:, step_size - 1, :]\n",
    "\n",
    "    np.savez('{}/data'.format(data_type), X=data, y=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped : 8597\n"
     ]
    }
   ],
   "source": [
    "make_data('Site_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped : 4\n"
     ]
    }
   ],
   "source": [
    "make_data('Site_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load('data/Site_1/data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       (18743, 5, 9)\n",
      "            (18743, 5, 9) (18743, 5, 9)\n",
      "            (37486, 5, 9) (18743, 5, 9)\n",
      "       (49759, 5, 9)\n",
      "            (49759, 5, 9) (49759, 5, 9)\n",
      "            (99518, 5, 9) (49759, 5, 9)\n",
      "       (42375, 5, 9)\n",
      "            (42375, 5, 9) (42375, 5, 9)\n",
      "            (84750, 5, 9) (42375, 5, 9)\n",
      "       (31690, 5, 9)\n",
      "            (31690, 5, 9) (31690, 5, 9)\n",
      "            (63380, 5, 9) (31690, 5, 9)\n"
     ]
    }
   ],
   "source": [
    "for test_site in [1, 23, 24, 25]:\n",
    "    tmp_X = None\n",
    "    tmp_y = None\n",
    "    for trn_site in [1, 23, 24, 25]:\n",
    "        if trn_site == test_site:\n",
    "            continue\n",
    "        data = np.load('data/Site_{}/data.npz'.format(test_site))\n",
    "        if tmp_X is None:            \n",
    "            tmp_X = data['X']\n",
    "            tmp_y = data['y']\n",
    "            print('      ', tmp_X.shape)\n",
    "        else:\n",
    "            print('           ', tmp_X.shape, data['X'].shape)\n",
    "            tmp_X = np.concatenate((tmp_X, data['X']), 0)\n",
    "            tmp_y = np.concatenate((tmp_y, data['y']), 0)\n",
    "            \n",
    "        \n",
    "    os.makedirs('data/merged_except_{}'.format(test_site))\n",
    "    np.savez('data/merged_except_{}/data'.format(test_site), X=tmp_X, y=tmp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18743, 5, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
